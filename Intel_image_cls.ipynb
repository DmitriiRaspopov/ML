{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Activation, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.utils import np_utils\n",
    "from keras import regularizers\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mchest_xray\u001b[0m/               \u001b[01;34mIntel_Image_classification\u001b[0m/  Pneumonia_CNN.ipynb\r\n",
      "\u001b[01;31mchest-xray-pneumonia.zip\u001b[0m  Intel_image_cls.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seg_train', 'seg_test', 'seg_pred']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"Intel_Image_classification/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['forest', 'glacier', 'buildings', 'sea', 'street', 'mountain']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"Intel_Image_classification/seg_train/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим списки изображений тренировочной выборки и изменим размер изображений с помощью cv2.resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train = []\n",
    "labels_train=[]\n",
    "label=0\n",
    "\n",
    "for directories in os.listdir(\"Intel_Image_classification/seg_train/\"):\n",
    "    if directories == \"glacier\":\n",
    "        label = 0\n",
    "    elif directories == \"sea\":\n",
    "        label = 1\n",
    "    elif directories == \"buildings\":\n",
    "        label = 2\n",
    "    elif directories == \"forest\":\n",
    "        label = 3\n",
    "    elif directories == \"street\":\n",
    "        label = 4\n",
    "    elif directories == \"mountain\":\n",
    "        label = 5\n",
    "        \n",
    "    for img in os.listdir(\"Intel_Image_classification/seg_train/\" + directories):\n",
    "        image = cv2.imread(\"Intel_Image_classification/seg_train/\" + directories + \"/\" + img)\n",
    "        image = cv2.resize(image,(150,150))\n",
    "        images_train.append(image)\n",
    "        labels_train.append(label)\n",
    "        Images_train, Labels_train = shuffle(images_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[219, 210, 207],\n",
       "        [221, 212, 209],\n",
       "        [223, 214, 211],\n",
       "        ...,\n",
       "        [225, 220, 219],\n",
       "        [225, 220, 219],\n",
       "        [226, 221, 220]],\n",
       "\n",
       "       [[220, 211, 208],\n",
       "        [221, 212, 209],\n",
       "        [222, 213, 210],\n",
       "        ...,\n",
       "        [222, 217, 216],\n",
       "        [222, 217, 216],\n",
       "        [223, 218, 217]],\n",
       "\n",
       "       [[221, 209, 207],\n",
       "        [221, 209, 207],\n",
       "        [222, 210, 208],\n",
       "        ...,\n",
       "        [220, 215, 214],\n",
       "        [220, 215, 214],\n",
       "        [220, 215, 214]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 30,  63,  72],\n",
       "        [ 12,  51,  59],\n",
       "        [ 38,  87,  95],\n",
       "        ...,\n",
       "        [ 14,  33,  36],\n",
       "        [ 29,  46,  49],\n",
       "        [ 50,  69,  72]],\n",
       "\n",
       "       [[ 38,  74,  82],\n",
       "        [ 34,  73,  81],\n",
       "        [ 35,  84,  92],\n",
       "        ...,\n",
       "        [ 39,  56,  59],\n",
       "        [ 41,  56,  59],\n",
       "        [ 52,  69,  72]],\n",
       "\n",
       "       [[ 31,  67,  75],\n",
       "        [ 51,  90,  98],\n",
       "        [ 24,  73,  83],\n",
       "        ...,\n",
       "        [ 51,  66,  69],\n",
       "        [ 38,  53,  56],\n",
       "        [ 36,  51,  54]]], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Images_train[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь то же самое, но только для тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_test = []\n",
    "labels_test = []\n",
    "label = 0\n",
    "\n",
    "for directories in os.listdir(\"Intel_Image_classification/seg_train/\"):\n",
    "    if directories == \"glacier\":\n",
    "        label = 0\n",
    "    elif directories == \"sea\":\n",
    "        label = 1\n",
    "    elif directories == \"buildings\":\n",
    "        label = 2\n",
    "    elif directories == \"forest\":\n",
    "        label = 3\n",
    "    elif directories == \"street\":\n",
    "        label = 4\n",
    "    elif directories == \"mountain\":\n",
    "        label = 5\n",
    "    \n",
    "    for img in os.listdir(\"Intel_Image_classification/seg_train/\" + directories):\n",
    "        image = cv2.imread(\"Intel_Image_classification/seg_train/\" + directories + \"/\" + img)\n",
    "        image = cv2.resize(image, (150,150))\n",
    "        images_test.append(image)\n",
    "        labels_test.append(label)\n",
    "        Image_test, Label_test = shuffle(images_test, labels_test)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нормализация данных (изображений) масштабирование\n",
    "\n",
    "Преобразование списка изображений в произвольную и нормализацию путем деления его на 255. Мы делим его на 255, потому что это цветное изображение, а цветовой диапазон составляет 0 - 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate array with shape (14034, 150, 150, 3) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-bd0e55ebde92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate array with shape (14034, 150, 150, 3) and data type float64"
     ]
    }
   ],
   "source": [
    "train_x = np.array(images_train)/255\n",
    "train_y = np.array(labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-14-52fedafb4dbd>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-52fedafb4dbd>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    train_x = np.array(images_train)./255\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "train_x = np.array(images_train)/255\n",
    "train_y = np.array(labels_train)\n",
    "\n",
    "test_x = np.array(images_test)/255\n",
    "test_y = np.array(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
